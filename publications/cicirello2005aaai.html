<!DOCTYPE html>
<html lang=en>
<head>
<meta charset=utf-8>
<link rel="canonical" href="http://www.cicirello.org/publications/cicirello2005aaai.html">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="title" content="The Max K-Armed Bandit: A New Model of Exploration Applied to Search Heuristic Selection - AAAI - 2005">
<meta name="description" content="The multiarmed bandit is often used as an analogy for the tradeoff between
exploration and exploitation in search problems. The classic problem involves
allocating trials to the arms of a multiarmed slot machine to maximize the
expected sum of rewards. We pose a new variation of the multiarmed bandit, the
Max K-Armed Bandit, in which trials must be allocated among the arms to
maximize the expected best single sample reward of the series of trials.
Motivation for the Max K-Armed Bandit is the allocation of restarts among a set
of multistart stochastic search algorithms. We present an analysis of this Max
K-Armed Bandit showing under certain assumptions that the optimal strategy
allocates trials to the observed best arm at a rate increasing double
exponentially relative to the other arms. This motivates an exploration
strategy that follows a Boltzmann distribution with an exponentially decaying
temperature parameter. We compare this exploration policy to policies that
allocate trials to the observed best arm at rates faster (and slower) than
double exponentially. The results confirm, for two scheduling domains, that the
double exponential increase in the rate of allocations to the observed best
heuristic outperforms the other approaches.">
<meta name="citation_title" content="The Max K-Armed Bandit: A New Model of Exploration Applied to Search Heuristic Selection">
<meta name="citation_author" content="Vincent A. Cicirello">
<meta name="citation_author" content="Stephen F. Smith">
<meta name="citation_publication_date" content="2005">
<meta name="citation_date" content="2005">
<meta name="citation_conference_title" content="The Proceedings of the Twentieth National Conference on Artificial Intelligence">
<meta name="citation_volume" content="3">
<meta name="citation_firstpage" content="1355">
<meta name="citation_lastpage" content="1361">
<meta name="citation_pdf_url" content="http://www.cicirello.org/publications/AAAI2005.pdf">
<meta name="citation_abstract_html_url" content="http://www.cicirello.org/publications/cicirello2005aaai.html">
<title>The Max K-Armed Bandit: A New Model of Exploration Applied to Search Heuristic Selection - AAAI - 2005</title>
<link rel="stylesheet" type="text/css" href="/styles/style.css">
</head>
<body>
<header id="siteheader">
<h2><a href="/">Vincent Cicirello, Ph.D. - Professor of Computer Science</a></h2>
<nav id="topNav">
<ul>
<li><a href="javascript:void(0);" onclick="toggleMenu()" class="menu-icon">&#9776;</a></li>
<li><a href="/">Home</a></li>
<li><a href="/publications/">Publications</a></li>
<li><a href="/research/">Research</a></li>
<li><a href="/datasets/">Datasets</a></li>
<li><a href="/software/">Open Source Software</a></li>
<li><a href="/teaching/">Teaching</a></li>
<li><a href="/past/">Past</a></li>
</ul>
</nav>
</header>
<article>
<header>
<h2>The Max K-Armed Bandit: A New Model of Exploration Applied to Search Heuristic Selection</h2>
<h3><a href="/">Vincent A. Cicirello</a> and Stephen F. Smith</h3>
<h4>In <i>The Proceedings of the Twentieth National Conference on Artificial Intelligence</i>, volume 3, pages 1355-1361. AAAI Press, July 2005.</h4>
<h4><strong>Winner of the 2005 AAAI Outstanding Paper Award</strong>.</h4>
</header>
<p><a href="/publications/AAAI2005.pdf">[PDF]</a> <a href="/publications/cicirello2005aaai.bib">[BIB]</a> <a href="http://www.aaai.org/Library/AAAI/2005/aaai05-215.php" target="_blank">[DOI]</a></p>
<h4>Abstract</h4>
<p>The multiarmed bandit is often used as an analogy for the tradeoff between
exploration and exploitation in search problems. The classic problem involves
allocating trials to the arms of a multiarmed slot machine to maximize the
expected sum of rewards. We pose a new variation of the multiarmed bandit, the
Max K-Armed Bandit, in which trials must be allocated among the arms to
maximize the expected best single sample reward of the series of trials.
Motivation for the Max K-Armed Bandit is the allocation of restarts among a set
of multistart stochastic search algorithms. We present an analysis of this Max
K-Armed Bandit showing under certain assumptions that the optimal strategy
allocates trials to the observed best arm at a rate increasing double
exponentially relative to the other arms. This motivates an exploration
strategy that follows a Boltzmann distribution with an exponentially decaying
temperature parameter. We compare this exploration policy to policies that
allocate trials to the observed best arm at rates faster (and slower) than
double exponentially. The results confirm, for two scheduling domains, that the
double exponential increase in the rate of allocations to the observed best
heuristic outperforms the other approaches.</p>
</article>

<aside>
<h3>Vincent A. Cicirello, Ph.D.</h3>
<h4>Current Position:</h4><br>
Professor of Computer Science and Information Systems<br><br>
<h4>Mailing Address:</h4><br>
School of Business<br>
Stockton University<br>
101 Vera King Farris Dr<br>
Galloway, NJ 08205<br><br>
<h4>E-mail:</h4>
<img src="/images/addr.png" width="177" height="19" alt="Contact address"><br><br>
<h4>Phone:</h4>
(609) 626-3526<br><br>
<h4>Social Media:</h4><br>
<a href="http://www.linkedin.com/in/vacicirello" target="_blank"><img src="https://static.licdn.com/scds/common/u/img/webpromo/btn_liprofile_blue_80x15.png" width="80" height="15" alt="View Vincent A. Cicirello's profile on LinkedIn"></a>
<a href="https://www.researchgate.net/profile/Vincent_Cicirello?cp=shp" target="_blank"><img alt="Follow me on ResearchGate" src="https://www.researchgate.net/images/public/profile_share_badge.png" width="120"></a>
</aside>

<footer>
<div id="w3css">
<a href="http://jigsaw.w3.org/css-validator/check/referer">
<img style="border:0;width:88px;height:31px"
src="http://jigsaw.w3.org/css-validator/images/vcss"
alt="Valid CSS!" >
</a>
</div>
<div id="copyright">Copyright &copy; 1998-<span id="year"></span> Vincent A. Cicirello.</div>
<script src="/js/year.js"></script>
<script src="/js/resp.js"></script>
</footer>
</body>
</html>

